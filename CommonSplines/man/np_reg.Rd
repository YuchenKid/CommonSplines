% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/nonparametric_regression.R
\name{np_reg}
\alias{np_reg}
\title{Nonparametric Regression using spline based methods}
\usage{
np_reg(x_train, y_train, x_test, func = "bs", order = 4, df = NULL,
  knots = NULL, lambda = 0.001, q = FALSE)
}
\arguments{
\item{x_train}{The input vector of training dataset.}

\item{y_train}{The output vector of training dataset.}

\item{x_test}{The input values at which evaluations are required.}

\item{func}{The name of regression functions. It can be "pbs" for power basis spline,
"ncs" for natural cubic spline, "css" for cubic smoothing spline, "bs" for B-spline. Default is "bs".}

\item{order}{The order that defines the spline. Default is 4.}

\item{df}{Degrees of freedom. One can supply df rather than knots.}

\item{knots}{The innerknots and boundary knots that define the spline.
The knots provided can be quantiles of x or real values.
More explanation of \code{knots}, \code{df}, \code{q} can be seen in \code{generate_knots}.}

\item{lambda}{The smoothing parameter for css. Default is 0.001.}

\item{q}{A boolean variable define whether \code{knots} provided are quantiles or real values. When \code{q}=TRUE, \code{knots}
provided are quantiles of x. When \code{q}=FALSE, \code{knots} provided are real values of x. Default is FALSE.}
}
\value{
\item{y_pred}{A vector of dimension length(x), the prediction vector evaluated at x_test values.}
}
\description{
This function provides regression using spline based methods. It finish both training procedure and predicting procedure.
Only univariate input can be used.
}
\examples{
x_train <- seq(1, 10, 0.1)
y_train <- cos(x_train)^3 * 3 - sin(x_train)^2 * 2 + x_train + exp(1)+rnorm(length(x_train),0,1)
plot(x_train,y_train)
title('Comparison of Different Degrees of Freedom')
x_test <- seq(1, 10, 0.1)
lines(x_test,cos(x_test)^3 * 3 - sin(x_test)^2 * 2 + x_test + exp(1),col="red")

df <- 2
y_pred <- np_reg(x_train, y_train, x_test,func="ncs", df=df)
lines(x_test,y_pred, col='blue')
df <- 4
y_pred <- np_reg(x_train, y_train, x_test,func="ncs", df=df)
lines(x_test,y_pred, col='green')
df <- 10
y_pred <- np_reg(x_train, y_train, x_test,func="ncs", df=df)
lines(x_test,y_pred, col='black')
legends <- c("Actual", "Prediction: 2 df", "Prediction: 4 df", "Prediction: 10 df")
legend('topleft', legend=legends, col=c('red', 'blue', 'green', 'black'), lty=1, cex=0.8)
}
\references{
"Friedman, J., Hastie, T., & Tibshirani, R. (2001). The elements of statistical learning (Vol. 1, pp. 337-387). New York: Springer series in statistics,"
Chapter 5.
}
\seealso{
\code{generate_knots}.
}
